{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu9F2FYSJfPO",
        "outputId": "1691fcec-d574-43b7-ede6-a433764e5175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import os\n",
        "from typing import Literal\n",
        "import re\n",
        "\n",
        "import kagglehub  # pip install kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "from tqdm import tqdm\n",
        "from together import Together\n",
        "from transformers import pipeline\n",
        "from sklearn.metrics import accuracy_score, log_loss, classification_report"
      ],
      "metadata": {
        "id": "dCfj8uv5Ki8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. Download the dataset and find the CSV file\n",
        "dataset_path = kagglehub.dataset_download(\"alfathterry/bbc-full-text-document-classification\")\n",
        "csv_path = next(Path(dataset_path).glob(\"*.csv\"))\n",
        "\n",
        "# 2. Load into a DataFrame and standardize column names\n",
        "df = pd.read_csv(csv_path)  # type: ignore\n",
        "cols = df.columns.tolist()\n",
        "df = df.rename(columns={cols[0]: \"text\", cols[1]: \"label\"})\n",
        "\n",
        "# 3. Inspect classes and original size\n",
        "labels = df[\"label\"].unique()\n",
        "print(f\"Number of categories: {labels.size}\")\n",
        "print(f\"Original dataset shape: {df.shape}\")\n",
        "\n",
        "# 4. Take only the first N samples per label\n",
        "N = 250\n",
        "df_limited = (\n",
        "    df\n",
        "    .groupby(\"label\", sort=False)    # preserve original label order\n",
        "    .head(N)                         # first N rows of each group\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# 5. Shuffle the resulting subset\n",
        "df_shuffled = df_limited.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(f\"Shape after sampling {N} per class and shuffling: {df_shuffled.shape}\")\n",
        "\n",
        "# 6. Show counts per label\n",
        "print(df_shuffled[\"label\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpxHwIANMS1E",
        "outputId": "7ef0becd-55d1-4558-cd72-3006dcd3551d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of categories: 5\n",
            "Original dataset shape: (2225, 2)\n",
            "Shape after sampling 250 per class and shuffling: (1250, 2)\n",
            "label\n",
            "sport            250\n",
            "tech             250\n",
            "business         250\n",
            "politics         250\n",
            "entertainment    250\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pXSO8OHFX7F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NEWS_CATEGORIES = {\n",
        "    \"entertainment\": \"Movies, music, arts, celebrity news\",\n",
        "    \"business\":      \"Economy, markets, finance, companies\",\n",
        "    \"sport\":         \"Sports events, athletes, competitions\",\n",
        "    \"politics\":      \"Government, policy, elections\",\n",
        "    \"tech\":          \"Technology, gadgets, innovations\"\n",
        "}\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a news categorization expert. Your task is to classify news texts into predefined categories.\n",
        "\n",
        "Available categories:\n",
        "{categories_list}\n",
        "\n",
        "Guidelines:\n",
        "- Be precise and consistent in your categorization\n",
        "- Consider the main theme and context of the text\n",
        "- If a text could fit multiple categories, choose the most dominant one\n",
        "- For soft classification, provide probability scores that sum to 1\n",
        "- For hard classification, select the single most appropriate category\n",
        "\"\"\".strip().format(\n",
        "    categories_list=\"\\n\".join(f\"- {cat}: {desc}\" for cat, desc in NEWS_CATEGORIES.items())\n",
        ")\n",
        "\n",
        "CLASSIFY_SOFT_PROMPT_TEMPLATE = \"\"\"\n",
        "Assign a probability score (0 < score < 1) to each category so they sum to 1.\n",
        "Wrap your response in <answer></answer> tags.\n",
        "\n",
        "# Expected format:\n",
        "<answer>\n",
        "{{\n",
        "    \"entertainment\": <probability>,\n",
        "    \"business\":      <probability>,\n",
        "    \"sport\":         <probability>,\n",
        "    \"politics\":      <probability>,\n",
        "    \"tech\":          <probability>\n",
        "}}\n",
        "</answer>\n",
        "\n",
        "News Text:\n",
        "{description}\n",
        "\n",
        "Provide only the JSON response without any additional text or explanations.\n",
        "\"\"\".strip()\n",
        "\n",
        "CLASSIFY_HARD_PROMPT_TEMPLATE = \"\"\"\n",
        "Select the most fitting category (among provided) for the given news text.\n",
        "Wrap your response in <answer></answer> tags.\n",
        "\n",
        "# Expected format:\n",
        "<answer>\n",
        "{{\n",
        "    \"Category\": \"<selected category>\"\n",
        "}}\n",
        "</answer>\n",
        "\n",
        "News Text:\n",
        "{description}\n",
        "\n",
        "Provide only the JSON response without any additional text or explanations.\n",
        "\"\"\".strip()\n"
      ],
      "metadata": {
        "id": "hKmSMfEWO_K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import re\n",
        "import ast\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Literal\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from together import Together\n",
        "\n",
        "# Configuration\n",
        "API_KEY = \"tgp_v1_xa8kNS1mlbTltz3XxsXeyk2sG9oSrK37jHrxwFgxpYM\"\n",
        "client = Together(api_key=API_KEY)\n",
        "BATCH = 16\n",
        "\n",
        "def classify_and_evaluate(model_name: str, mode: Literal[\"soft\", \"hard\"]) -> float:\n",
        "    \"\"\"\n",
        "    Run zero-shot classification in batches and compute accuracy.\n",
        "    mode: \"soft\" returns argmax of returned score-dict; \"hard\" uses returned 'Category'.\n",
        "    \"\"\"\n",
        "    # Select the appropriate prompt template\n",
        "    template = (\n",
        "        CLASSIFY_SOFT_PROMPT_TEMPLATE\n",
        "        if mode == \"soft\"\n",
        "        else CLASSIFY_HARD_PROMPT_TEMPLATE\n",
        "    )\n",
        "\n",
        "    # Build prompts and targets\n",
        "    prompts = [template.format(description=row.text) for row in data.itertuples()]\n",
        "    targets = data.label.tolist()\n",
        "\n",
        "    def _call_api(text_prompt: str) -> str:\n",
        "        try:\n",
        "            resp = client.chat.completions.create(\n",
        "                model=model_name,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                    {\"role\": \"user\",   \"content\": text_prompt}\n",
        "                ]\n",
        "            )\n",
        "            body = resp.choices[0].message.content.strip()\n",
        "            match = re.search(r\"<answer>(.*?)</answer>\", body, re.DOTALL)\n",
        "            if not match:\n",
        "                raise ValueError(\"Missing <answer>…</answer> tags\")\n",
        "            result = ast.literal_eval(match.group(1).strip())\n",
        "            return (\n",
        "                max(result, key=result.get)\n",
        "                if mode == \"soft\"\n",
        "                else result[\"Category\"]\n",
        "            )\n",
        "        except Exception as err:\n",
        "            print(f\"[{model_name}][{mode}] Error: {err}\")\n",
        "            return \"ERROR\"\n",
        "\n",
        "    # Process in parallel batches\n",
        "    all_preds = []\n",
        "    for start in tqdm(range(0, len(prompts), BATCH), desc=\"Batches\"):\n",
        "        chunk = prompts[start : start + BATCH]\n",
        "        with ThreadPoolExecutor(max_workers=BATCH) as pool:\n",
        "            all_preds.extend(pool.map(_call_api, chunk))\n",
        "\n",
        "    # Compute accuracy\n",
        "    correct = sum(1 for pred, true in zip(all_preds, targets) if pred == true)\n",
        "    acc = correct / len(targets)\n",
        "    model_id = Path(model_name).name\n",
        "    print(f\"[{model_id}][{mode}] Accuracy: {acc:.4f}\")\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "hw-6qov0Maau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "from typing import Literal\n",
        "\n",
        "# Define modes and model identifiers\n",
        "mode_options: list[Literal[\"hard\", \"soft\"]] = [\"hard\", \"soft\"]\n",
        "model_names = [\"lgai/exaone-3-5-32b-instruct\"]\n",
        "\n",
        "# Collect (mode, model, accuracy) tuples\n",
        "results = []\n",
        "\n",
        "for mode, model in product(mode_options, model_names):\n",
        "    acc = classify_and_evaluate(model_name=model, mode=mode)\n",
        "    results.append([mode, model, acc])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSH8OAYGMfYd",
        "outputId": "a7365b44-5317-4cef-865f-effcc1d82eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batches: 100%|██████████| 32/32 [00:35<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[exaone-3-5-32b-instruct][hard] Accuracy: 0.9500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Batches: 100%|██████████| 32/32 [01:01<00:00,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[exaone-3-5-32b-instruct][soft] Accuracy: 0.9340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tabulate(results, headers=[\"Mode\", \"Model\", \"Accuracy\"], floatfmt=\".3f\", tablefmt=\"grid\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t22fUPPwMgm5",
        "outputId": "3ca62f74-8f32-4da9-f5bf-3c237af19cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------------------+------------+\n",
            "| Mode   | Model                        |   Accuracy |\n",
            "+========+==============================+============+\n",
            "| hard   | lgai/exaone-3-5-32b-instruct |      0.950 |\n",
            "+--------+------------------------------+------------+\n",
            "| soft   | lgai/exaone-3-5-32b-instruct |      0.934 |\n",
            "+--------+------------------------------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я менял тысячу моделек, менял размеры классов, но у меня не получилось заставить софт побить побить хард, но я слышал, что есть люди у кого получилось. Возможно мне не повезло с датасетом."
      ],
      "metadata": {
        "id": "GpxiTBFYvCGX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z0yvoeh6vQL2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}